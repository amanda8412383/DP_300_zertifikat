{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1e27f3",
   "metadata": {},
   "source": [
    "# lesson 6 configure azure sql db for scale and performance\n",
    "\n",
    "**note:backup storage redundancy** \n",
    "\n",
    "geo redundant backup will replicate the storage to a paired region (e.g. US East to Us West) in case of data storage damaging\n",
    "\n",
    "**note:billing type** \n",
    "- provisional charged based on vcore\n",
    "- serverless charged based on second, shut down after 1 hr inactivity, restarted takes a little time\n",
    "\n",
    "\n",
    "**note:hybrid benefit** \n",
    "- it's a Microsoft licensing program that allows customers to use their existing on-premises Windows Server and SQL Server licenses with active Software Assurance or subscription to reduce costs when running those workloads in Azure\n",
    "- can only work with vcore, not with dtu\n",
    "**note:elastic pool** \n",
    "\n",
    "- let manage multiple db resource allocation possible, so they could share resource when one not using it\n",
    "- not possible for hyperscale\n",
    "- can select edtu (elastic dtu) in setting\n",
    "- unit price for edut compared to dtu is extra 50 %, vcore have same unti price\n",
    "- if a DTU db peak at different time, elastic pool could be a good idea, otherwise it's more expensive due to unit price\n",
    "- unavailable at hyperscale\n",
    "\n",
    "\n",
    "\n",
    "### storage purchasing model\n",
    "- can be changed later, except changed out of hyperscale\n",
    "- change should be done at a low trafic time\n",
    "- after change DMV(dynamic management view) needed to be flushed for accurate estimation\n",
    "exec sq_query_store_flush\n",
    "##### DTU (database transaction unit)based\n",
    "- DTU can be adjusted with related S tier\n",
    "- CDC (changed data captured) can't be used when having less than 100 DTB (= S3 = 1vcore)\n",
    "- when using more than 300 DTU, vcore might be a cheaper option\n",
    "- plan selection can based on peak usage and storage need, the latter could be estimate with average data use * db number \n",
    "1. Basic: up to 2GB\n",
    "Development, testing, infrequently accessed workload\n",
    "2. Standard\n",
    "3. Premium\n",
    "suitable when more iops (inputs output per second) is needed\n",
    "##### vCore (virtual core) based\n",
    "- max data storgae and core could be specified\n",
    "- core decide max data storgae ceiling & tempdb size\n",
    "- log space is 30% of the max data stoarge\n",
    "- hardware choice affect memory, core number and storage\n",
    "- iops = concurrent number of request, this can't be configured, but go up with vcore\n",
    "\n",
    "4. general purpose: 80 vcore, 4 terabyte storage\n",
    "suitable for low latency input\n",
    "5. Hyperscale: 80 vcore, 100 terabyte storage\n",
    "6. Business critical: 80 vcore, 4 terabyte storage, fast geo-recovery and advanced data corruption protection, free second read-only replica\n",
    "Business critical has high transaction rate and high resiliency, is suitable for large number/long-running transaction\n",
    "\n",
    "### connection\n",
    "\n",
    "- TLS transport level security"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
