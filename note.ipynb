{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1e27f3",
   "metadata": {},
   "source": [
    "# lesson 6 configure azure sql db for scale and performance\n",
    "\n",
    "**note:backup storage redundancy** \n",
    "\n",
    "geo redundant backup will replicate the storage to a paired region (e.g. US East to Us West) in case of data storage damaging\n",
    "\n",
    "**note:billing type** \n",
    "- provisional charged based on vcore\n",
    "- serverless charged based on second, shut down after 1 hr inactivity, restarted takes a little time\n",
    "\n",
    "\n",
    "**note:hybrid benefit** \n",
    "- it's a Microsoft licensing program that allows customers to use their existing on-premises Windows Server and SQL Server licenses with active Software Assurance or subscription to reduce costs when running those workloads in Azure\n",
    "- can only work with vcore, not with dtu\n",
    "**note:elastic pool** \n",
    "\n",
    "- let manage multiple db resource allocation possible, so they could share resource when one not using it\n",
    "- not possible for hyperscale\n",
    "- can select edtu (elastic dtu) in setting\n",
    "- unit price for edut compared to dtu is extra 50 %, vcore have same unti price\n",
    "- if a DTU db peak at different time, elastic pool could be a good idea, otherwise it's more expensive due to unit price\n",
    "- unavailable at hyperscale\n",
    "\n",
    "\n",
    "\n",
    "### storage purchasing model\n",
    "- can be changed later, except changed out of hyperscale\n",
    "- change should be done at a low trafic time\n",
    "- after change DMV(dynamic management view) needed to be flushed for accurate estimation\n",
    "exec sq_query_store_flush\n",
    "##### DTU (database transaction unit)based\n",
    "- DTU can be adjusted with related S tier\n",
    "- CDC (changed data captured) can't be used when having less than 100 DTB (= S3 = 1vcore)\n",
    "- when using more than 300 DTU, vcore might be a cheaper option\n",
    "- plan selection can based on peak usage and storage need, the latter could be estimate with average data use * db number \n",
    "1. Basic: up to 2GB\n",
    "Development, testing, infrequently accessed workload\n",
    "2. Standard\n",
    "3. Premium\n",
    "suitable when more iops (inputs output per second) is needed\n",
    "##### vCore (virtual core) based\n",
    "- max data storgae and core could be specified\n",
    "- core decide max data storgae ceiling & tempdb size\n",
    "- log space is 30% of the max data stoarge\n",
    "- hardware choice affect memory, core number and storage\n",
    "- iops = concurrent number of request, this can't be configured, but go up with vcore\n",
    "\n",
    "4. general purpose: 80 vcore, 4 terabyte storage\n",
    "suitable for low latency input\n",
    "5. Hyperscale: 80 vcore, 100 terabyte storage\n",
    "6. Business critical: 80 vcore, 4 terabyte storage, fast geo-recovery and advanced data corruption protection, free second read-only replica\n",
    "Business critical has high transaction rate and high resiliency, is suitable for large number/long-running transaction\n",
    "\n",
    "### table partitioning\n",
    "\n",
    "- a table have 3 elements storage space, computing resource limit (exceeing might lead to timeout) and network bandwidth limit\n",
    "- vertical scaling by adding disc space, processing power, memory and network connection could be a short term solution\n",
    "- horizontal scaling by divifing the table up according to rule e.g. by year, it add up complexity but reduce hardware demand\n",
    "- back up per partition is also faster \n",
    "- the other option is to split the table columns up\n",
    "\n",
    "### database  sharding\n",
    "- when we apply horizontal scaling on db level\n",
    "- there would be a table with shard key, and where they are stored, this require more setting up \n",
    "- range strategy is diving by range e.g.years, sequential shard, data might be unblanced when there is seasonality\n",
    "- hashing strategy introduce random element for distribution, it reduce hotspot bcs no cluster would be more used, but rebalancing and manging mmight be difficult, when looking up a value the results are all over places\n",
    "- functional partitioning, not putting all the tables in the same db, e.g. seperate tables that needs extra security\n",
    "- keeping data geographically close can reduce latency when using\n",
    "\n",
    "**note: file group**\n",
    "- can't be used in Azure SQL db (only primary file group there)\n",
    "- file can be putted in file group to define partition range rules and where to store\n",
    "\n",
    "### compression for table\n",
    "- pro reduced space\n",
    "- con takes extra power and time to compress and retrieve \n",
    "- can't be used on table with sparse columns\n",
    "- changing compression require droping clustered index\n",
    "- complete index viewed can be compressed\n",
    "- system table can't be compressed\n",
    "- table with different partition can be compressed differently\n",
    "- *exec sp_estimate_data_compression_savings* help estimate compression effect\n",
    "\n",
    "method:\n",
    "1. no compression\n",
    "2. row compression: char and nchar columns would be greatly reduced, varchar and int not so much, date types depends, tiny int not at all\n",
    "3. page compression which includes (below element can't be activated seperately):\n",
    "    1. row compression\n",
    "    2. prefix compression: store long duplicated value in a specific column as prefix key, and generate an extra table for prefix key to long name to prevent the duplication of long char storage\n",
    "    3. dictionary compression: similar to prefix compression, but instead of on a specific column, the duplication would be searched across columns and keys would be used for whole table\n",
    "\n",
    "    - page is a set of row up to 8192 character\n",
    "    - uncompressed at first, when additional rows can't be fit in, compression takes place\n",
    "    - some older version SQL server on VM is this unavailable\n",
    "\n",
    "**note heap**\n",
    "haep is table without clustered index\n",
    "\n",
    "**columnstore table**\n",
    "above are row stored table. in columnstore table, columns are always compress, which could be further compressed through columnstore archival compression (but this has super high compute cost for uncompress)\n",
    "\n",
    "### SQL data sync\n",
    "- works for Azure SQL, on-prem or VM, but not with management instance\n",
    "- allows sync across db\n",
    "- primary key is required\n",
    "- must define a hub db and multiple member dbs\n",
    "- rules can be defined which direction to sync, e.g. change would be replicated from hub to member or member to hub, but not directly between members\n",
    "- rule when hub and member simultaneously changed should be defined\n",
    "- sync metadata db is an azure sql db whihc loacte in the same region as hub and store, should be empty at start\n",
    "- for on perm or vm member db, a syn agent programm is needed \n",
    "- on azure db page syncing db could be created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c84b1",
   "metadata": {},
   "source": [
    "# lesson 7 strategy of migration \n",
    "\n",
    "### migration tools\n",
    "\n",
    "| purpose    | tool | extra function |\n",
    "| -------- | ------- | ------- |\n",
    "| lift & shift sql server to vm   | azure migrate    |   assess sql data estate at scale(across data center)/getting azure sql deployment recommendation, target sizing & monthly estimate  |\n",
    "| non sql objects (DB2, MYSQL, Oracle, SAP, ASE) to sql/azure sql, each are independent download program | sql server migration system     ||\n",
    "| sql server object to sql db/managed instance/vm/on prem     | data migration system    |upgrade SQL/assess sql data estate at scale/ performance & reliability improvement recommendation/ detect incompatibility of target/ migrate on-prime/ discover new feature on target|\n",
    "| compare workloads between source and target  | database experiementation assistant    | |\n",
    "| open source db (mysql, postgresql, mariadb) to azure offline/online (premium price tier)  | azure db migration service    ||\n",
    "\n",
    "1. azure migrate  \n",
    "- consists of 2 tools: discovery & assessment, server migration\n",
    "**azure migrant hub** includes azure migration assistant & azure db migration service\n",
    "\n",
    "2. sql server migration system \n",
    "\n",
    "3. data migration system\n",
    "- for large size data azure db migration service  would be better option\n",
    "\n",
    "4. database experiementation assistant \n",
    "\n",
    "5. azure db migration service \n",
    "- princing tier standard provides up to 4 vcore for free, but only support offline migration\n",
    "- princing tier premium provides up to 4 vcore with 6 month free trial, support offline & online\n",
    "\n",
    "| from    | to | online (continuous sync)    | offline (one-time) |\n",
    "| -------- | ------- | -------- | ------- \n",
    "| SQL server  | azure sql db    | x  | v    |\n",
    "| SQL server    | azure sql db mi    | v | v    |\n",
    "| SQL server    | azure sql vm  | x  | v    |\n",
    "| mongodb    | azure cosmos db  | v | v    |\n",
    "| mySQL    | azure db for mySQL  | x  | v   |\n",
    "| postgreSQL    | azure db for postgresql  | v  | x  |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**reminder** if not latest SQL is needed, then VM must be used and a window version needed to be decide\n",
    "\n",
    "**note** \n",
    "- without downtime allowance, the only way is to do an online migration\n",
    "- if cross db dependecy exist, azure db is not a good option, as it doesn't allow cross db queries\n",
    "- for azure db migration service, allow outbond port 443 = port for https or 1434 used for UDP, then enable TCP IP protocal, next create azure SQL db instance which needs a server level firewall rule on depature db/server & contorl server permission on depature server to allow access to DMS and on target db control db permission is needed. it use exsiting full log backup instead of creating new one\n",
    "- there are other service e.g. Bulk copie programm, command bulk insert, log data from Azure blob storage, SQL server integration service package, spark/azure factory\n",
    "- migrant stuff directly between Azure SQL db can use export or export data tier application (which allow export of schema), or export form azure portal, download and using SQLpackage\n",
    "- export data tier application (DAC) will make the export as .bacpac (backup package) file\n",
    "\n",
    "### post migration\n",
    "1. have tests to make sure data are there\n",
    "2. checking Query returns same result in sourece and target db\n",
    "3. checking the performance\n",
    "4. changing the app connecting to db from departure db to target db\n",
    "5. checking missin features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585db218",
   "metadata": {},
   "source": [
    "### lesson 8 Microsoft Entra ID\n",
    "\n",
    "\n",
    "### authn = authentication = log in\n",
    "1. window authentication\n",
    "    - on a window machine/domain \n",
    "    - in azure only on VM is window available\n",
    "2. SQL sever authentication\n",
    "    - using username and password\n",
    "3. azure active directory\n",
    "    - setting could be access through azure portal, e.g. adding user\n",
    "    - more secure than SQL sever authentication and can select way to authenticate in portal \n",
    "    - once the AAD admin is setted through azure portal (only 1 admin allow), the admin can log in SSMS through (other log in method won't allow role creation) and create more roles through query \n",
    "    - comparison between AAD admin and sql server admin:\n",
    "        - both could create users based on SQL server authentication log in\n",
    "        - both can create contained DB users based on SQL server authentication wo log in\n",
    "        - AAD admin can create contained DB users based on aad users and group\n",
    "    - authentication methods includes FIDO secutity keys which is a hardware on computer, microsoft authenticator, text message and temporary access pass\n",
    "    - can sync with on-prem windows server active directory\n",
    "    - when we are logging in azure portal is a form of azure active directory\n",
    "    - azure active directory - integrated/universal with MFA(multi factor authentication) can be used when using admin tool like SSMS on a computer that is not domain joined \n",
    "    - 3 different way to authenticate in:\n",
    "        1. cloud only identity\n",
    "            - handle sign in completely in cloud by azure\n",
    "        2. federated authentication\n",
    "            - integrate with existing federation provider\n",
    "            - sign in requirement which is not native supported by Azure active directory\n",
    "        3. pass-through authentication\n",
    "            - when don't have a sign-in requirement not natively supported by Azure active directory\n",
    "            - and want to enforce extra feature like user level active directory sign in policy\n",
    "    - identity: \n",
    "        1. cloud only identity\n",
    "        2. hybrid identity support both cloud authentication & pass-through authentication\n",
    "        3. hybrid identity support federated authentication\n",
    "    - to create a user based on AAD user use: create user [user_email] from external provider\n",
    "4. window server active directory\n",
    "\n",
    "**note:**\n",
    "- authz = autherization = what one could access\n",
    "\n",
    "### role\n",
    "-  when running on an non-azure machine that is domain joined by creating a certificate and connect the app to azure data\n",
    "- to see all role in azure SQL use sp_helprole\n",
    "- after creating user, adding roles for the user is needed in SQL server\n",
    "    - alter role [role name] add/drop member [member email]\n",
    "    1. db_owner : have access to all.\n",
    "    2. db_securityadmin : modify role membership for custom roles only. manage permission, can elevate own permission\n",
    "    3. db_accessadmin: add & remove access to db for login & groups\n",
    "    4. db_backup_operator: not applicable in azure. can backup db, mi & vm\n",
    "    5. db_ddladmin: can run ddl comment (creat, alter, drop)\n",
    "    6. db_data_reader: can read all data\n",
    "    7. db_deny_data_reader: can't read old data\n",
    "    8. db_data_writer: ability to add, delete or change data\n",
    "    9. db_deny_data_writer: can't add, delete or change data\n",
    "    - on-prem only, roles that exist in master db\n",
    "    10. db_manager: create/delete db\n",
    "    11. login_manage: create/delete login in master db = security_admin for master db\n",
    "- role based access control (RBAC) in azure:\n",
    "    - Access control section is called IAM, when role could be added\n",
    "    - there is no access to server wide logging permission bc access to underlying server doesn't exist\n",
    "    1. SQL DB contributer: allow SQL DB, but don't have access to content\n",
    "    2. SQL server contributer: allow SQL server/security policy manage, but don't have access to content\n",
    "    3. SQL security manager: allow SQL security policy manage, but don't have access to content\n",
    "\n",
    "### granting permission\n",
    "- granting access to particular schema/table can't be achieved through these set roles in stead grant permission command should be used\n",
    "- command: authorization permission on securable::name to pricipal with grant option\n",
    "- select * from sys.fn_my_permissions(null, 'DATABASE') shows all permission\n",
    "1. autherization (grant, revoke, deny)\n",
    "    - grant [permission_type] on object::[schema].[table] to [user_email]\n",
    "    - to revoke the permission used revoke [permission_type] on object::[schema].[table] to [user_email]\n",
    "    - to ban someone from table access that cannot be overwrite by grant use deny [permission_type] on object::[schema].[table] to [user_email]\n",
    "2. permission \n",
    "    - table: select, insert, update, delete, control(all right to table), reference(view foreignkey), take ownership(change ownership), view change tracking, view definition (rightclick and go to script table path)\n",
    "    - schema: alter(=alter/create/drop any securable)\n",
    "    - function/stored procedure: alter, execute(even lack of select permission on table is not a problem, this is called ownership changing), view change tracking, view definition\n",
    "3. securable (object, schema, db, server)\n",
    "4. principal (login, user, role: create role [rolename], add member [useremail])\n",
    "    - public is a special role that every single user of the db have this role\n",
    "5. with grant option: allow the principal to share the permission later\n",
    "\n",
    "**note:apply principal of least privilige for all securable**\n",
    "a user should have least privilige user account (LUA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1cbe2",
   "metadata": {},
   "source": [
    "### lesson 9 implement security\n",
    "\n",
    "### transparent data encryption (tde)\n",
    "- this is the security for data in transit\n",
    "- it encrypts then deencrypts data at page level at rest\n",
    "- encrypts at write then decrypts at read\n",
    "- for azure SQL db this is set at server level, new db inheritate the rule unless recover from a copy, encryption can be turn off in azure portal / Tsql / cloudshell / restapi\n",
    "- for azure sql mi this is set at instance level,  new db inheritate the rule but not system db, encryption can be turn off  in Tsql/ cloudshell/ restapi\n",
    "- it use database encryption key (dek), which is a symetric key = one single key is needed for en- & decrypts\n",
    "    - this could be a service managed key, protected by a TDE protector using service managed certificate \n",
    "    - this could be a bring your own key, in this case it could also be asymmetric\n",
    "\n",
    "**note** transparent layer security (TLS), encrypts when in transit\n",
    "\n",
    "### object level encryption (e.g. table with sensitive data)\n",
    "1. always encrypted\n",
    "    - always encrypted is available in azure sql db, mi, vm\n",
    "    - this could be done in ssms through right click encrypt columns\n",
    "    - encryption type has deterministic (encryption is the same everytime, allows for join, group by, index, distinct without decrypt) & random \n",
    "    - when the column is used as index, it can't be randomized encrypt\n",
    "    - to create encryption, key vault is needed\n",
    "    - after creation, next time when connecting to db in SSMS select enable alway encrypt \n",
    "    - a pricipal (e.g. user) need to be in key vault to decrypt encrypted colunm\n",
    "\n",
    "    - to query an encrypted column in where clause, set up a parameter & enable parameterlization for always encrypted is needed, but this will still block funtion like\n",
    "    - to enable partial string comparison, always encrypted need to be used with secure enclaves\n",
    "        1. enable confidential computing through configured as DC series\n",
    "            - strongest security isolation\n",
    "            - type name is intel software guard intellegence(sgx)\n",
    "            - require ms azure attestation\n",
    "        2. enable secure enclaves in a standard configure db\n",
    "            - type name is virtualization based security (vbs)\n",
    "            - available for all ay sql, and sql 2019+\n",
    "            - not available in ger india central\n",
    "            - can't defend against e.g. replacing enclaves program with malware\n",
    "            - creating a protected part of memory within which data is display as plain text\n",
    "            - protection against operative system threat\n",
    "            - standard azure protection (e.g. multifactor authentication, just in time access)\n",
    "            - can't be deactivated after activation\n",
    "\n",
    "    - permission wise there are\n",
    "        1. alter any column master key\n",
    "        2. alter any column encryption key\n",
    "        3. view any column master/encryption key (for access, query and read encrypted data)\n",
    "    - role wise there are\n",
    "        1. security admin who generate column encryption key and master key, access to key and key store are required, access to db is not required\n",
    "        2. db admin who manage metadata about key, access to key and key store isn't required, access to db is required\n",
    "        - if these 2 role should belongs to 2 ppl, then powershell should be used\n",
    "        - if these 2 role should belongs to same ppl, then powershell or ssms could be used\n",
    "\n",
    "2. dynamic data masking\n",
    "    - this could be done through azure portal \n",
    "    - in tsql: alter table [schema].[table] alter column [column] add masked with (fuction = 'default()')\n",
    "    - it can be apply on specific column with desired partial masking 2025-0x-1x\n",
    "    - specific users could be excluded in azure portal/tsql: grant(/revoke) unmask to [useremail] \n",
    "    - this could also be done through powershell\n",
    "### key vault \n",
    "- could be created in azure sql portal\n",
    "- in key vault store secrets\n",
    "- key vault name need to be unique\n",
    "- better store it in region near db\n",
    "- pricing tier premium allow use of hardware security model (HSM). it's the same as standard  until hsm is used\n",
    "- in access policy selecting unwrap key + wrap key + verify + sign (and also the default selections) is necessary to column create primary key \n",
    "\n",
    "\n",
    "| | always encrpted    | transparent data encrpytion (tde) |\n",
    "| -------- | ------- |------- |\n",
    "| sql server version  |  2016+   | 2008+ |\n",
    "| sql server entriprise edition | x     | v|\n",
    "| free in azure sql db    | v    | v|\n",
    "| protect data at rest   | v   | v |\n",
    "| protect data in use    | v  | x (when in transport, using transport layer security) |\n",
    "| protect data from sql admin  | v  | x |\n",
    "| data is de/encrypted on the client side  | v | x|\n",
    "| data is de/encrypted on the server side   | x | v |\n",
    "| encrypt at    | column level  | entire db|\n",
    "| transparent to application   | partially | v |\n",
    "| encryption option   | v | x |\n",
    "| key management   | customer managed keys | server/customer managed keys |\n",
    "| protects key in use  | v | x |\n",
    "| driver required | v |  x|\n",
    "\n",
    "\n",
    "### configure server level firewall\n",
    "- by default all connection are rejected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49534a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
